\section{Langzeitverhalten}

\newcommand{\stat}{\underline{\pi}} % stationäre Wahrscheinlichkeit

Dieser Abschnitt beschäftigt sich mit der \link{def:mk-vert}{Verteilung der
Markovkette} nach unendlich vielen Schritten.

\textbf{Achtung: Die hier verwendete
Notation weicht zum Teil deutlich von den Vorlesungsvideos ab.}

\begin{definition}{Stationäre Verteilung}{mk-stat}
Sei $(X)_{n\in N_0}$ eine Markovkette mit \link{def:mk-matr}{Übergangsmatrix}
$\Pi$ und endlichem Zustandsraum $S$. Dann heißt die
\link{def:mk-vert}{Verteilung} $\stat$ \defw{stationäre Verteilung},
wenn gilt:
\[
\stat\cdot\Pi = \stat
\]
\end{definition}

Gelangt oder startet man in einer stationären Verteilung, ändert sich die
Wahrscheinlichkeit, sich in einem Zustand zu befinden, nicht mehr.

\subsection{Ergodische Markovketten}

\begin{theorem}{Hauptsatz für ergodische Markovketten}{ergod}
Sei $(X)_{n\in N_0}$ eine \link{def:mk-ergod}{ergodische} Markovkette mit
\link{def:mk-matr}{Übergangsmatrix} $\Pi$ und $y$ ein Zustand der Markovkette
mit \link{def:mk-rueckk}{Rückkehrzeit} $T_y$. Dann
besitzt die Markovkette \emph{genau} eine stationäre Verteilung $\stat$
für die gilt:
\[
\lim_{n\to\infty}\Pi(X_n = y) = lim_{n\to\infty}\Pi^n(x, y) = \stat(y)
\]
Weiterhin existiert ein Zusammenhang zwischen der erwarteten Rückkehrzeit und
der stationären Verteilung:
\[
\stat(y) = \frac{1}{\E(T_y|X_0=y)}
\]
\end{theorem}

Je weiter eine ergodische Markovkette läuft, desto mehr nähert sich die
Wahrscheinlichkeitsverteilung an die stationäre Verteilung an. Die stationäre
Verteilung gibt – zumindest auf lange Sicht – an, mit welcher Wahrscheinlichkeit
man sich in den jeweiligen Zuständen befindet.

Die stationäre Verteilung einer ergodischen Markovkette kann berechnet
werden. Dafür nutzt man die Tatsache, dass die stationäre Verteilung (per
Definition) ein Eigenvektor\more{mfnf-ew-ev} der Übergangsmatrix. Zusätzlich
muss wird eine Gleichung eingefügt, die die Normierung der stationären
Verteilung auf 1 sicherstellt. Es ergibt sich folgendes
lineares Gleichungssystem:
\begin{equation}\label{eq:stat-lgs}
\begin{pmatrix}
\Pi_{00}-1 & \Pi_{10} & \ldots & \Pi_{j0} \\
\Pi_{01} & \Pi_{11}-1 &        & \Pi_{j1} \\
\vdots   &            & \ddots & \vdots \\
\Pi_{0i} & \Pi_{1i} & \ldots &   \Pi_{ji}-1 \\
    1    &     1    & \ldots &   1
\end{pmatrix}\cdot \vec{\stat} = \begin{pmatrix}0\\0\\\vdots\\0\\1\end{pmatrix}
\end{equation}
Wichtig ist auch, dass die Matrix $\Pi$ transponiert aufgeschrieben, da eine
Spalte der Matrix einer Gleichung entspricht.

\subsection{Nichtergodische Markovketten}

\newcommand{\lzv}{\Pi^\infty} % Langzeitverhalten

Bei Nichtergodischen Markovketten ist das Langzeitverhalten nicht so einfach
bestimmbar, da die stationäre Verteilung vom Startzustand abhängt. Das
Langzeitverhalten der Markovkette wird durch die Matrix $\lzv$ beschrieben,
die für jeden möglichen Startzustand die entsprechende Langzeitverteilung
angibt.

\medskip
Sei $(X)_{n\in N_0}$ eine Markovkette mit endlichem Zustandsram $S$ und
\link{def:mk-matr}{Übergangsmatrix} $\Pi$, wobei $T\subseteq S$ die Menge aller
\link{def:mk-trans}{transienten} Zustände ist. Es gelten die nachfolgende Regeln
zur Bestimmung des Langzeitverhaltens.

In einer \link{def:mk-abg}{abgeschlossenen} Klasse $C$ kann das
Langzeitverhalten als \link{def:mk-stat}{stationäre Verteilung}
$\stat^{(C)}$ der auf die Zustände in $C$ beschränkten Markovkette bestimmt
werden (vergleiche \eqref{eq:stat-lgs}):
\begin{equation}\label{eq:lzv-abg-abg}
  \forall x,y\in C: \lzv(x,y) = \stat^{(C)}(y)
\end{equation}
Da eine \link{def:mk-abg}{abgeschlossene} Klasse $C$ nicht
verlassen werden kann, gilt für $x\in C$ und $y \notin C$:
\begin{equation}\label{eq:lzv-abg-x}
  \lzv(x,y) = 0
\end{equation}
Damit ist das Langzeitverhalten der Startzustände in abgeschlossenen Klassen
bestimmt.

\medskip
Das Langzeitverhalten bei Start in einem \link{def:mk-trans}{transienten}
Zustand $t\in T$ muss die
Wahrscheinlichkeit der Absorption durch eine abgeschlossene Klasse $C$
berücksichtigt werden, die mit $p_{abs}(t,C)$ bezeichnet wird. Die
Absorptionswahrscheinlichkeit berechnet sich rekursiv als Wahrscheinlichkeit des
direkten Übergangs in die absorbierende Klasse plus die Wahrscheinlichkeit des
indirekten Übergangs mit einem zusätzlichen Schritt innerhalb der transienten
Klasse:
\[
p_{abs,t}(C) = \sum_{y\in C} \Pi(x,y) + \sum_{z\in T}\Pi(x,z)\cdot p_{abs,z} \\
\]
Für alle $t$ einer transienten Klasse entsteht so ein Gleichungssystem.

Die Wahrscheinlichkteit, bei Start in $t$ in $y\in S$ zu
enden, berechnet sich durch die Absorptionswahrscheinlichkeit verknüpft mit
der stationären Wahrscheinlichkeit $\stat^{(C)}$ innerhalb von $C$:
\begin{equation}\label{eq:lzv-trans-abg}
\lzv(x,y) = p_{abs,t}(C)\cdot\stat^{(C)}(y)
\end{equation}
Die Wahrscheinlichkeit, sich in einem \link{def:mk-trans}{transienten}
Zustand zu befinden, sinkt auf lange Sicht auf 0:
\begin{equation}\label{eq:lzv-trans-trans}
\forall x\in S, y\in T: \lzv(x, y) = 0
\end{equation}
Damit ist das Langzeitverhalten für den Start in einem transitiven Zustand
definiert.
Da in endlichen Markovketten alle abgeschlossenen Klassen rekurrent sind
\warn{Begründung bzw. Beweis fehlt}, sind
durch die obigen Definitionen das Langzeitverhalten bestimmt.

\begin{example}{Langzeitverhalten einer nichtergodischen Markovkette}{mk-lzv-nerg}
Gegeben sei folgende Markovkette:

\begin{minipage}{0.45\textwidth}
  \begin{tikzpicture}
    \node[v] (1) at (0,1.5) {1};
    \node[v] (2) at (-1.5,0) {2};
    \node[v] (3) at (0,0) {3};
    \node[v] (4) at (1.5,0) {4};

    \draw[e] (1) to[loop above] ();
    \draw[e] (2) to[loop below] ();
    \draw[e] (3) to[loop below] ();
    \draw[e] (4) to[loop below] ();
    \draw[e] (1) -- (2);
    \draw[e] (1) -- (3);
    \draw[e] (1) -- (4);
    \draw[e] (2) to[bend left] (3);
    \draw[e] (3) to[bend left] (2);
  \end{tikzpicture}
\end{minipage}
\begin{minipage}{0.45\textwidth}
  \[\Pi = \begin{pmatrix}
    0.1 & 0.4 & 0.3 & 0.2 \\
     0  & 0.2 & 0.8 &  0  \\
     0  & 0.9 & 0.1 &  0  \\
     0  &  0  &  0  &  1
  \end{pmatrix}\]
\end{minipage}

Die Markovkette ist nicht \link{def:mk-irred}{irreduzibel}, da mehr als eine
Klasse existiert ($S_{/\lr} = {S_1, S_{2,3}, S_{4}}$), Satz \ref{satz:ergod}
kann also nicht angewandt werden.

\medskip
Da Klasse $S_4$ abgeschlossen und Zustand 4 absorbierend ist, ergibt sich als
Sonderfall von \eqref{eq:lzv-abg-abg} und \eqref{eq:lzv-abg-x} folgende
Verteilung:
\[\begin{pmatrix}0 & 0 & 0 & 1\end{pmatrix}\]

Klasse $S_{2,3}$ ist abgeschlossen. Die stationäre Verteilung $\stat^{(S_{2,3})}$
ergibt sich als Lösung des Gleichungssystems (Vergleiche \eqref{eq:stat-lgs})
und bestimmt $\lzv(2..3, 2..3)$:
\[
\begin{pmatrix}
0.2 -1 & 0.9     \\
0.8    & 0.1 - 1 \\
   1   &  1
\end{pmatrix}\cdot \vec{\stat}^{(S_{2,3})} = \begin{pmatrix}0\\0\\1\end{pmatrix}
\iff \vec{\stat}^{(S_{2,3})} =
\renewcommand\arraystretch{1.3}
\begin{pmatrix}0.53\\0.47\end{pmatrix}
\]

Zustand 1 ist transient, damit gilt $\lzv(1,1) = 0$
(\eqref{eq:lzv-trans-trans}). Als Zwischenergebnis bestimmen wir die
Absorptionswahrscheinlichkeiten $p_{abs,1}(S_{2,3})$ und $p_{abs,1}(S_{4})$:
\begin{align*}
p_{abs,1}(S_{2,3}) &=&  0.4 + 0.3 + 0.1 \cdot p_{abs,1}(S_{2,3}) & \implies
p_{abs,1}(S_{2,3}) = \frac{0.7}{0.9} = 0.78  \\
p_{abs,1}(S_{4})   &=&  0.2 + 0.1 \cdot p_{abs,1}(S_4) &\implies
p_{abs,1}(S_4) =\frac{0.2}{0.9} = 0.22
\end{align*}
Durch Anwendung von Gleichung \eqref{eq:lzv-trans-abg} ergibt sich:
\begin{align*}
\lzv(1,2) &=& p_{abs,1}(S_{2,3}) &\cdot\stat^{(S_{2,3})}(2) &= 0.41 \\
\lzv(1,3) &=& p_{abs,1}(S_{2,3}) &\cdot\stat^{(S_{2,3})}(3) &= 0.37 \\
\lzv(1,4) &=& p_{abs,1}(S_4)     &\cdot\stat^{(S_4)}    (4) &= 0.22
\end{align*}
Damit sind alle Einträge der Matrix $\lzv$ bestimmt:
\[
\lzv = \begin{pmatrix}
   0  & 0.41 & 0.37 & 0.22 \\
   0  & 0.53 & 0.47 &  0   \\
   0  & 0.53 & 0.47 &  0   \\
   0  &  0   &  0   &  1
\end{pmatrix}
\]
Als Probe kann sichergestellt werden, dass die Matrix stochastisch ist, sich
also die Einträge jeder Zeile zu 1 summieren.
\end{example}
